---
layout: page
title: 詳細の職務経歴書
---

## ■ スキル概要

### 【クラウド / インフラ】

- AWS（実務 4 年）
  - Compute / Container: `EC2`, `ECS(Fargate)`, `Lambda`, `ECR`
  - Networking / DNS / LB: `VPC`, `ALB`, `Route 53`
  - Storage / DB / Cache: `S3`, `EFS`, `RDS`, `ElastiCache`
  - Security / Identity: `IAM`, `IAM Identity Center`, `KMS`, `WAF`, `Secrets Manager`
  - Integration / Messaging: `EventBridge`
  - Monitoring / Audit: `CloudWatch`, `CloudTrail`
  - Governance / Cost / Migration: `Control Tower`, `Billing and Cost Management`, `DMS`
  - （IaC は下記「【IaC】」参照: `CloudFormation`）

- Google Cloud（個人学習）
  - Compute / Serverless: `Cloud Run`, `Cloud Run Jobs`, `Cloud Functions`, `Compute Engine`
  - Storage / DB: `Cloud Storage`, `Cloud SQL`, `Bigtable`
  - Networking / DNS: `Cloud DNS`
  - Messaging: `Pub/Sub`
  - Observability: `Cloud Logging`, `Cloud Monitoring`
  - IAM / Billing: `IAM`, `Billing`

### 【コンテナ】

- Docker（実務）

※EKSは学習中

### 【IaC】

- CloudFormation（実務）
- Terraform（個人学習・ポートフォリオ作成中）

### 【CI/CD】

- Jenkins（ジョブ設計〜自動デプロイ）
- GitHub Actions（個人学習で使用）

### 【監視 / Observability】

- CloudWatch（ログ・メトリクス）
- Datadog（学習中）

### 【その他】

- Linux（基本操作）
- Shell Script
- Git / GitHub

---

## 今後の目標

### 短期目標（1-2 年）

- **Infrastructure as Code (IaC) の実践・推進**
- **クラウドネイティブ技術の深掘り**

### 中期目標（3-5 年）

- **監視・可観測性の向上**
- **SRE 的なアプローチでの信頼性向上とパフォーマンス最適化**

### 長期目標（5 年以上）

- **インフラと SRE のスペシャリスト**
- **信頼される技術的エキスパート**

---

## 詳細職務経歴

### 1. 保険基盤システム AWS 移行プロジェクト（現在参画中） {#proj1}

**設計判断の要点（採用理由/トレードオフ/代替案）**

- コンテナ基盤は ECS/ECR を採用。運用容易性と立ち上げ速度を優先（代替: EKS）。拡張性はやや低いが、要件内で十分と判断。
- 共有ストレージは EFS を採用。アプリ改修最小化を優先（代替: S3 + アプリ改修 / FSx）。性能コストはモニタリング前提で許容。
- ロードバランサーは Web 系に ALB を標準化（代替: NLB）。L7 のヘルスチェックとルーティング柔軟性を重視。
- データベースは RDS/Aurora を採用。可用性/バックアップ/運用負荷を総合評価（代替: EC2 自前運用）。
- CI/CD は組織制約を踏まえ Jenkins を採用（代替: GitHub Actions）。コンプライアンス要件と既存資産活用を優先。

**失敗からの学び/標準化に落とした点**

- 初期は手順の属人化でリードタイムばらつき。標準手順/テンプレートと変更申請フローを整備。
- IAM 権限設計の粒度不一致がレビュー負荷に影響。ロール/ポリシー命名規則とレビュー観点を標準化。

**プロジェクト概要**:

| 項目                 | 内容                                                                                                                  |
| -------------------- | --------------------------------------------------------------------------------------------------------------------- |
| **期間**             | 約 1 年（現在進行中）                                                                                                 |
| **プロジェクト規模** | インフラチーム 6 名（+リーダー 1 名）<br>                                                                             |
|                      | アプリチーム 17 名（+リーダー 3 名）<br>                                                                              |
|                      | テストチーム 10 名（+リーダー 1 名）                                                                                  |
| **役割**             | インフラチームメンバー                                                                                                |
| **担当領域**         | AWS 環境設計・構築、CI/CD 環境整備                                                                                    |
| -------------------- | --------------------------------------------------------------------------------------------------------------------- |
| **期間**             | 約 1 年（現在進行中）                                                                                                 |
| **プロジェクト規模** | インフラチーム 6 名（+リーダー 1 名）<br>アプリチーム 17 名（+リーダー 3 名）<br>テストチーム 10 名（+リーダー 1 名） |
| **役割**             | インフラチームメンバー                                                                                                |
| **担当領域**         | AWS 環境設計・構築、CI/CD 環境整備                                                                                    |

**技術的取り組み**

- AWS ECS/ECR 環境構築
  - ECS クラスターのパラメータ設計、タスク定義作成、ヘルスチェック設定
  - 保険システムの高可用性要件を満たすため、マルチ AZ 配置とヘルスチェック間隔を 30 秒に設定
  - ECR リポジトリ作成、Java アプリケーションのコンテナイメージ管理設計
  - DMSを使用し、オンプレミス環境のデータベースの移行前評価とDMSの実行

- 共有ファイルシステム設計
  - AWS EFS の設計・構築、アプリケーションログ出力用ディレクトリ構成設計
  - 複数の ECS タスク間でログファイルを共有する必要があるため、EFS を選択し、パフォーマンスモードを汎用に設定

- CI/CD 環境整備
  - Jenkins デプロイメントスクリプトの改修、コンテナプッシュからタスク定義更新までの自動化実装
  - 手動での ECR プッシュ作業を自動化し、デプロイ時間を従来の 30 分から 10 分に短縮

**成果物・改善施策**

- インフラ構築ドキュメント
  - IaaS 基盤チーム向け構築申請書、客先提出用の構築手順書・パラメータシート
  - 他チームメンバーでも同様の構築が可能となるよう、手順を詳細化・標準化

- ソースコード管理プロセス
  - GitHub 上での構築スクリプト・設定ファイル管理、プルリクエストによる変更管理プロセス確立
  - コードレビュー必須化により、設定ミスによる障害を未然防止

**定量的成果**

- プロジェクトで 4 つのショットに分けられたもので、3 ショット分の全環境 AWS 環境構築完了
- 構築プロセス標準化により、チーム全体の作業効率が約 40%向上
- CI/CD 自動化により、デプロイ作業時間を 67%短縮（30 分 →10 分）
- ドキュメント整備により、新規参画メンバーの立ち上がり期間を 2 週間から 1 週間に短縮

**技術的成長**

- クラウドネイティブ設計思想の習得
- ECS/ECR を活用したコンテナ管理の実践的スキル
- Jenkins + AWS サービスを組み合わせた CI/CD パイプライン構築経験

---

### 2. AWS 業務基盤 新規・追加構築、保守 {#proj2}

**設計判断の要点（採用理由/トレードオフ/代替案）**

- 立ち上げ速度と社内標準の整合から EC2 + Ansible を採用（代替: ECS/EKS）。運用自動化で保守コストを抑制。
- 高可用性要件に対し Aurora マルチ AZ を標準化（代替: 単一 AZ / 自前 DB）。コスト増は停止リスク低減で相殺。
- IaC は CloudFormation を選択（代替: Terraform）。既存自動構築ツール連携を優先。将来的に Terraform 併用を検討。
- CI は Jenkins を採用（代替: GitHub Actions）。社内運用ノウハウと承認フローを活かす判断。
- セキュリティは職務分離と最小権限を厳格運用。運用効率とのトレードオフはロール分割で調整。

**失敗からの学び/標準化に落とした点**

- RHEL9 で Ansible 実行エラー多発。OS バージョン別変数/タスクの事前分岐とプリフライトチェックを標準化。
- 本番申請判断が属人化。フローシート/チェックシートで再鑑ポイントを明文化し、判断時間を短縮。

**プロジェクト概要**

| 項目                 | 内容                                                                                 |
| -------------------- | ------------------------------------------------------------------------------------ |
| **期間**             | 約 1 年                                                                              |
| **プロジェクト規模** | 12 名のスクラムチーム（+スクラムマスター 1 名）<br>他 4 チームと連携（全体約 60 名） |
| **役割**             | インフラエンジニア                                                                   |
| **担当領域**         | 新規システム構築・既存システム追加構築・廃止システムリソース削除                     |

**技術的取り組み**

- AWS インフラ構築・運用
  - 社内自動構築ツールを使用した新規 AWS 環境構築（EC2、RDS、VPC 等）
  - 銀行の高可用性要件を満たすため、Aurora（PostgreSQL/MySQL）を選択し、マルチ AZ 構成を標準化

- 自動化・運用効率化
  - EC2 + Ansible によるアプリケーションサーバー構築・設定変更の自動化
  - 手動設定作業を自動化することで、設定ミスを防止し作業時間を短縮

- セキュリティ設計
  - AWS IAM によるユーザー・ロール・ポリシー管理、最小権限の原則に基づくアクセス制御設計
  - 銀行のセキュリティ要件に対応するため、職務分離の原則を適用し、必要最小限の権限付与を徹底

**改善施策・成果**

- ナレッジベース構築・運用
  - 特殊対応事例の issue 管理システム構築、週次 AWS 定例での全 5 チーム（約 60 名）への展開
  - RHEL9 対応における Ansible 実行エラー解決

- 課題発見から解決まで
  - EC2（RHEL9）に対して Ansible 実行時、大量のエラーが発生
  - RHEL8 で適用していた設定項目が RHEL9 では不要・非対応となったことを特定
  - OS バージョン別の設定差分を詳細分析し、実行前のコメントアウト対応を標準化

- プロセス標準化
  - 本番作業申請の判断フローシート、作業種別ごとの再鑑ポイントマニュアル
  - チーム内の認識統一を図り、申請可否の判断時間を短縮

- 品質管理体制の構築
  - 作業種別ごとのチェックシート導入、抜け漏れ防止の仕組み構築
  - 過去の作業ミス事例を分析し、予防策をチェックリスト化

**定量的成果**

- 新規システム構築、既存システム追加構築、廃止システムリソース削除の完了
- インフラ安定性向上：Aurora 導入により可用性 99.9%を達成
- 作業効率向上：標準化により作業時間を平均 30%短縮
- 品質向上：チェックシートにより作業ミスを 80%削減
- ナレッジ共有効果：週次定例での情報展開により、類似課題の解決時間を 50%短縮
- 新人育成の効率化：マニュアルにより新人の立ち上がり期間を 2 週間短縮
- セキュリティ強化：IAM 権限見直しにより不要なアクセス権限を 70%削減
- 他チームへの波及効果：RHEL9 対応の知見共有により、全体で約 40 時間の作業時間削減を実現

**技術的成長**

- AWS 実務経験ゼロからのスタートだったが、計画的学習により急速にスキルを習得
- AWS サービス全般（EC2、RDS、VPC、IAM、S3、Load Balancer、CloudFormation）の実践的運用
- Ansible を活用した構成管理とデプロイメント自動化
- 銀行業務に適した高品質・高セキュリティなインフラ運用手法

---

### 3. Windows Server 更改業務 {#proj3}

**設計判断の要点（採用理由/トレードオフ/代替案）**

- 可用性は Windows Failover Clustering を採用（代替: 外部クラスタ製品）。ネイティブ機能で運用複雑性を抑制。
- DB は DB2 を AIX から移行。互換性重視でパラメータを Windows 前提に最適化（代替: 別 RDBMS 置換）。
- 監視/運用は JP1 を採用（代替: OSS 監視）。大規模運用と既存運用資産の継承を優先。
- 設計資産は AIX 設計書をトレースしつつ Windows 用テンプレートへ再構成。後続作業の再現性を確保。
- 本番切替は検証環境でのフェイルオーバーテスト完了をゲートに設定（代替: 一括移行）。

**失敗からの学び/標準化に落とした点**

- AIX 前提の設定が混入しかけた課題を教訓化。Windows 向け設計テンプレート/レビュー観点/パラメータ差分表を整備。
- 監視運用手順のばらつきを是正。JP1 ジョブ/通知/復旧手順をテンプレート化し、教育に組み込み。

**プロジェクト概要**

| 項目                 | 内容                                                                                |
| -------------------- | ----------------------------------------------------------------------------------- |
| **期間**             | 約 2 年                                                                             |
| **プロジェクト規模** | インフラチーム 5 名（+リーダー 1 名）<br>ミドルウェアチーム 25 名（+リーダー 1 名） |
| **役割**             | インフラチームメンバー                                                              |
| **担当領域**         | Windows Server 環境構築・DB2 移行・JP1 運用管理システム導入                         |

**技術的取り組み**

- Windows Server 2019 環境構築
  - 約 20 台のサーバーに対する OS インストール・初期設定、Active Directory 統合
  - 高可用性要件を満たすため、Windows Failover Clustering を採用し、2 ノードクラスタ構成を標準化
  - グループポリシー設定、共有ストレージ設定、フェイルオーバーテスト実施

- IBM DB2 移行・構築
  - DB2 のインストール・初期構築、AIX からのパラメータ移行・最適化調整
  - AIX 環境の DB2 パラメータを分析し、Windows 環境に適合するよう調整・最適化
  - クラスタ環境での DB2 構築により、システム停止リスクを最小化

- JP1 運用管理システム導入
  - JP1/Base、JP1/IM 導入・設定、監視ジョブ設定、アラート通知設定
  - 運用自動化スクリプト作成により、手動監視作業を大幅削減
  - 従来の手動監視から自動監視への移行により、運用負荷を軽減

**改善施策・成果**

- 情報収集体制の構築
  - チーム内での技術課題・懸念点の定期的な吸い上げ体制確立
  - ベンダーサポートへの体系的な問い合わせプロセスを構築
  - 得られた回答の文書化・チーム内共有による知見蓄積システムを整備

- 設計資産の標準化
  - AIX 基本・詳細設計書の分析と Windows 環境への適合性評価
  - パラメータシートのプラットフォーム間差分を詳細に整理・文書化
  - Windows 用設計書テンプレートの作成・標準化により、後続作業の効率化を実現

- 移行リスク管理
  - 各システムの移行前に検証環境での十分な動作確認を実施
  - フェイルオーバーテストを含む包括的なテストにより、本番環境での安定稼働を担保

**定量的成果**

- 全 20 システムの AIX から Windows 環境への移行完了
- レガシーシステムのモダナイゼーション達成
- 予定通りのプロジェクト完了
- システム可用性向上：クラスタ構成により可用性 99.5%を達成（従来比 15%向上）
- 運用効率化：JP1 により手動監視作業を 80%削減
- 移行品質向上：検証プロセスにより全 20 システムの移行を予定通り完了、ダウンタイムを計画値以内に抑制
- 設計書整備：標準化により、AIX 設計書から Windows 設計書への変換作業を 100%完了
- 問題解決の効率向上：サポート問い合わせ体制により、技術課題の平均解決時間を 3 日短縮

**技術的成長**

- マルチプラットフォーム対応力：Unix 系と Windows 系の技術的差分を理解し、適切な移行戦略を立案・実行
- システム統合技術：異なるプラットフォーム間でのデータベース移行、運用管理システム統合
- 高可用性設計：Windows Failover Clustering を活用したシステム可用性向上
- 制約下での情報収集：限られた情報源の中で、確実な技術情報を収集・活用する手法を確立
- リスク管理：不確実性の高い移行プロジェクトにおいて、段階的検証によるリスク最小化を実現

---

### 4. データセンター 運用・保守業務 {#proj4}

**設計判断の要点（採用理由/トレードオフ/代替案）**

- エスカレーションマトリクスと責任分界を明確化（代替: 現場裁量）。初動速度と判断品質を両立。
- 予防保守と障害切り分けガイドを標準化（代替: 都度対応）。キャリア回線の停止リスクを抑制。
- 監視は重要度/影響度で閾値と通知先を定義。誤検知/過剰通知を抑制。
- 交代制の属人化対策として作業手順/引継テンプレートを整備。オンボーディングを短縮。
- 定期の事例共有会でナレッジを横展開。再発防止と判断基準の統一を実現。

**失敗からの学び/標準化に落とした点**

- 過剰エスカレーション/判断迷いを教訓化。基準明確化で無駄なエスカレーションを大幅削減。
- 属人化による対応遅延を是正。ローテーション/チェックリスト/訓練を運用標準に組み込み。

**プロジェクト概要**

| 項目                 | 内容                                                                                   |
| -------------------- | -------------------------------------------------------------------------------------- |
| **期間**             | 約 2 年                                                                                |
| **プロジェクト規模** | 10 名の輪番体制チーム                                                                  |
| **役割**             | 当初はチームメンバー、最終的に**チームリーダー**として業務を統括                       |
| **担当領域**         | 最大手キャリアから委託された回線保守・障害対応と、顧客独自システムの運用保守を並行実施 |

**技術的取り組み**

- ネットワーク監視・運用管理
  - 約 500 台の通信機器・サーバーの 24 時間監視、ルーター・スイッチの一次交換・設定確認
  - キャリアグレードの可用性要件を満たすため、予防保守と迅速な障害対応を重視
  - ノード監視システムの運用、キャリア回線の品質監視・障害切り分け

- 障害対応・エスカレーション管理
  - ネットワーク・サーバー障害の一次切り分け、保守ベンダーへの適切なエスカレーション
  - 迅速かつ正確な初期対応により、障害影響範囲の最小化を実現
  - 顧客からの障害報告受付・初期対応における確実性の担保

- 顧客対応・レポーティング
  - 技術的な問い合わせ対応、運用状況・障害統計のレポート作成
  - 顧客満足度の向上のため、迅速かつ正確な情報提供を重視

**リーダーとしてのマネジメント実績**

- 業務標準化の推進
  - 客先と直接協議し、実運用に即したマニュアルへの全面改訂を主導
  - マニュアル見直し：現場の実態と乖離していた既存マニュアルを、実運用ベースで再構築
  - 手順書の体系化：障害種別ごとの対応フローを明文化・標準化し、判断迷いを排除
  - チェックリスト導入：作業漏れ防止のための確認項目整備により、品質の均一化を実現

- 責任分界点の最適化
  - 客先との協議により、業務負荷の適正化と責任範囲の明確化を実現
  - 案件別の責任範囲調整：過度な業務負荷を客先と協議して適正レベルに調整
  - エスカレーション基準明確化：判断に迷わない明確な基準設定により、対応時間を短縮
  - チーム内の役割分担見直し：個人の強みを活かした効率的な業務配分により、生産性を向上

- チームマネジメント強化
  - 高離職率環境での持続可能な運用体制構築を実現
  - ナレッジ共有体制：定期的な事例共有会の開催により、チーム全体のスキル底上げを実現
  - 新人育成プログラム：段階的なスキル習得カリキュラム策定により、独り立ち期間を短縮
  - 負荷分散の仕組み化：属人化防止のためのローテーション制度導入により、安定運用を実現

**定量的成果**

- 24 時間 365 日のデータセンター安定運用の継続
- キャリアグレードの高可用性要求への確実な対応
- 約 500 台の機器に対する継続的な監視・保守の実現
- 障害対応時間の短縮：標準化により平均対応時間を 40%短縮（60 分 →36 分）
- エスカレーション精度向上：基準明確化により無駄なエスカレーションを 70%削減
- チーム生産性向上：属人化解消により、新人の独り立ち期間を 3 週間短縮
- 顧客満足度の向上：問い合わせ対応標準化により、顧客満足度 95%以上を維持
- 運用品質の安定化：マネジメントによりサービス可用性 99.9%以上を継続達成

**リーダーシップとマネジメント経験**

- 組織課題の解決力
  - 持続可能な運用体制構築：高離職率環境において、属人化を排除した安定運用体制を構築
  - ステークホルダー管理：客先との交渉を通じた業務改善により、組織レベルでの根本的な課題解決を実現
  - 品質とコストの両立：標準化による効率化と、キャリアグレード品質の維持を同時に達成

- チームマネジメントスキル
  - 人材育成：新人育成プログラムの策定により、短期間での戦力化を実現
  - 負荷分散管理：個人の強みを活かした業務配分により、チーム全体の生産性を最大化
  - 継続的改善：定期的な振り返りと改善により、運用品質の継続的向上を実現

- 技術リーダーとしての成長
  - 技術と管理の両立：現場での技術業務を継続しながら、チーム全体のマネジメントを効果的に実施
  - プロセス改善力：現場の課題を分析し、標準化とプロセス改善により根本的解決を実現
  - 組織影響力：個人の技術力向上とチーム全体の生産性向上を両立し、組織全体への価値提供を達成
